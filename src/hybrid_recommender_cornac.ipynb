{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cornac\n",
    "from cornac.datasets import movielens\n",
    "from cornac.metrics import Recall, Precision, MAE, RMSE\n",
    "from cornac.models import ItemKNN, MF\n",
    "from cornac.models import Recommender\n",
    "from cornac.eval_methods import RatioSplit"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear modelos propios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "class MeanRecommender(Recommender):\n",
    "    def __init__(self, name=\"MeanRecommender\"):\n",
    "        super().__init__(name=name)\n",
    "        self.item_means = None\n",
    "\n",
    "    def fit(self, train_set, val_set):\n",
    "        super().fit(train_set, val_set)\n",
    "        # Calcular la media de las calificaciones para cada ítem\n",
    "        self.item_means = np.zeros(train_set.num_items)\n",
    "        for i in range(train_set.num_items):\n",
    "            ratings = train_set.matrix[:, i].data\n",
    "            if len(ratings) > 0:\n",
    "                self.item_means[i] = np.mean(ratings)\n",
    "            else:\n",
    "                self.item_means[i] = 0\n",
    "\n",
    "    def score(self, user_id, item_id=None):\n",
    "        if item_id is None:\n",
    "            return self.item_means\n",
    "        return self.item_means[item_id]\n",
    "    \n",
    "class Hybrid(cornac.models.Recommender):\n",
    "    def __init__(self, mf_model, knn_model, name=\"Hybrid\"):\n",
    "        super().__init__(name=name)\n",
    "        self.mf_model = mf_model\n",
    "        self.knn_model = knn_model\n",
    "\n",
    "    def fit(self, train_set, eval_set):\n",
    "        super().fit(train_set,eval_set)\n",
    "        self.mf_model.fit(train_set, eval_set)\n",
    "        self.knn_model.fit(train_set, eval_set)\n",
    "\n",
    "    def score(self, user_idx, item_idx=None, fraction=(10, 1)):\n",
    "        mf_scores = self.mf_model.score(user_idx, item_idx)\n",
    "        knn_scores = self.knn_model.score(user_idx, item_idx)\n",
    "        total = sum(fraction)\n",
    "        return (mf_scores*fraction[0] + knn_scores*fraction[1])/total\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el dataset de MovieLens 100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "data = movielens.load_feedback()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir el método de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "ratio_split = RatioSplit(data=data, test_size=0.2, rating_threshold=4.0, exclude_unknowns=True, verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los modelos a emplear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "mean_recommender = MeanRecommender() # Modelo propio\n",
    "mf = MF(k=10, max_iter=25, learning_rate=0.01, lambda_reg=0.02)\n",
    "svd = cornac.models.SVD()\n",
    "knn = ItemKNN(k=20, similarity='cosine', name='ItemKNN')\n",
    "bpr = cornac.models.BPR(k=10, max_iter=25, learning_rate=0.01, lambda_reg=0.02)\n",
    "hybrid = Hybrid(mf_model=mf, knn_model=knn)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir las metricas a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "metrics = []\n",
    "metrics.append(MAE())\n",
    "metrics.append(RMSE())\n",
    "metrics.append(Recall(10))\n",
    "metrics.append(Precision(10))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir el experimento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "experiment = cornac.Experiment(eval_method=ratio_split, models=[mean_recommender, mf, bpr, svd, knn, hybrid], metrics=metrics)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "experiment.run()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer los resultados de las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "results = experiment.result\n",
    "mean_mae = results[0].metric_avg_results['MAE']\n",
    "mean_rmse = results[0].metric_avg_results['RMSE']\n",
    "mean_precision = results[0].metric_avg_results['Precision@10']\n",
    "mf_mae = results[1].metric_avg_results['MAE']\n",
    "mf_rmse = results[1].metric_avg_results['RMSE']\n",
    "mf_precision = results[1].metric_avg_results['Precision@10']\n",
    "bpr_mae = results[2].metric_avg_results['MAE']\n",
    "bpr_rmse = results[2].metric_avg_results['RMSE']\n",
    "bpr_precision = results[2].metric_avg_results['Precision@10']\n",
    "svd_mae = results[3].metric_avg_results['MAE']\n",
    "svd_rmse = results[3].metric_avg_results['RMSE']\n",
    "svd_precision = results[3].metric_avg_results['Precision@10']\n",
    "knn_mae = results[4].metric_avg_results['MAE']\n",
    "knn_rmse = results[4].metric_avg_results['RMSE']\n",
    "knn_precision = results[4].metric_avg_results['Precision@10']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un gráfico de barras para mostrar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "metrics_names = ['MF_MAE', 'MF_RMSE', 'MF_Pr', 'BPR_MAE', 'BPR_RMSE', 'BPR_Pr', 'MEAN_MAE', 'MEAN_RMSE', 'MEAN_Pr', 'SVD_MAE', 'SVD_RMSE', 'SVD_Pr', 'KNN_MAE', 'KNN_RMSE', 'KNN_Pr']\n",
    "values = [mf_mae, mf_rmse, mf_precision, bpr_mae, bpr_rmse, bpr_precision, mean_mae, mean_rmse, mean_precision, svd_mae, svd_rmse, svd_precision, knn_mae, knn_rmse, knn_precision] \n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.bar(metrics_names, values, color=['blue', 'purple', 'red', 'blue', 'purple', 'red', 'blue', 'purple', 'red', 'blue', 'purple', 'red', 'blue', 'purple', 'red'])\n",
    "plt.xlabel('Métricas')\n",
    "plt.ylabel('Valores')\n",
    "plt.title('Resultados de las Métricas del Sistema de Recomendación')\n",
    "plt.show()\n"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
